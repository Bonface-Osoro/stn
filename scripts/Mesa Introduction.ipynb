{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e6bd50a",
   "metadata": {},
   "source": [
    "First, we import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "988cbd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import mesa\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mesa import Agent, Model\n",
    "from mesa.datacollection import DataCollector\n",
    "from mesa.space import MultiGrid\n",
    "from scipy.spatial.distance import cdist, squareform\n",
    "from mesa.time import RandomActivation # mesa.time governs model time ticks.  The RandomActivation means that \n",
    "                                       # which agents go first in each time tick is randomly decided"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9a0acd",
   "metadata": {},
   "source": [
    "We create a function that returns 0 or 1 which is the course of action assigned to the agent on initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7f5f9871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def course_of_action():\n",
    "    \"\"\"This function returns the course of action assigned \n",
    "       to the agent on initialization.\n",
    "       \n",
    "    Returns\n",
    "    -------\n",
    "    action_course : list\n",
    "        Action taken by the agent.\n",
    "    \"\"\"\n",
    "    choices = [0, 1] #0 interception, 1 no interception\n",
    "    # 80% interception and 20% no interception by the bad agent\n",
    "    action_course = random.choices(choices, weights = [90, 10])[0]\n",
    "    \n",
    "    return (action_course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d3b694f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiploModel(Model):\n",
    "    \n",
    "    \"\"\"\n",
    "    This class Initializes the model as an instance of the \n",
    "    mesa.Model class. It include the following helper \n",
    "    functions: __id_matrix, \n",
    "    \"\"\"\n",
    "    \n",
    "    def __id_matrix(self):\n",
    "        \"\"\"This function calculates the inverse distance \n",
    "           matrix of 1 over twice the distance.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        ewise_dist : tuple\n",
    "            Elementwise distance between two cells (array).\n",
    "        \"\"\"\n",
    "        \n",
    "        ## Gets the list of coordinates in the MultiGrid for the model and converts it into an array so we can \n",
    "        ## use the cdist function\n",
    "        cell_list = list(self.grid.coord_iter())\n",
    "        coords = [(cell[1],cell[2]) for cell in cell_list]\n",
    "        np_coords = np.array(coords)\n",
    "        \n",
    "        ## cdist calculates the elementwise distance between two arrays - here we're just doing it between the array\n",
    "        ## and itself, which gives us the distance matrices for each cell. Then convert the 0s to 1s to prevent \n",
    "        ## by zero, and take the inverse division\n",
    "        ewise_dist = cdist(np_coords, np_coords)*2\n",
    "        ewise_dist[ewise_dist == 0] = 1\n",
    "        ewise_dist = (1 / ewise_dist)\n",
    "        \n",
    "        return ewise_dist\n",
    "    \n",
    "    def __valence_sum(self):\n",
    "        \"\"\"This function directly accesses the model's \n",
    "           grid.coord_iter method and iterate over it. \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        cell_valence : tuple\n",
    "            Valence values for each cell.\n",
    "        \"\"\"\n",
    "        cell_valence = copy.deepcopy(self.empty) # Instantiates IDW as a deepcopy of the 1d array of zeroes\n",
    "\n",
    "        for cell in self.grid.coord_iter():\n",
    "            \n",
    "            ## Each cell in the grid has three attributes - a list of cell contents, the x and y coordinates,\n",
    "            cell_content, x, y = cell\n",
    "            cell_valence[x][y] = (sum([agent.valence for agent in cell_content]))\n",
    "            \n",
    "        return cell_valence\n",
    "    \n",
    "    def __IDW_matrix(self):\n",
    "        \"\"\"This function calculates the inverse distance \n",
    "           weights for each cell of the matrix.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        IDW_results : tuple\n",
    "            Inverse distance weighted values for that one \n",
    "            layer in a flattened array.\n",
    "        \"\"\"\n",
    "        IDW = copy.deepcopy(self.empty.flatten())\n",
    "        \n",
    "        #for every layer in the inverse distance cube, multiply the inverse distance and the\n",
    "        ## agent counts together.  \n",
    "        for i in range(len(self.id_matrix)):\n",
    "            IDW_layer = np.multiply(self.id_matrix[i], self.valence_sum.flatten()[i])\n",
    "            \n",
    "            ## Add array elementwise\n",
    "            IDW = np.add(IDW, IDW_layer) \n",
    "            \n",
    "            ## Then, reshape it so it has the same dimensions as the model grid so we can extract neighborhood\n",
    "            ## cell values, which will inform how the agent moves.\n",
    "            agent_moves = (IDW.reshape(self.grid.width,self.grid.height))\n",
    "            \n",
    "        return agent_moves\n",
    "    \n",
    "    def __get_ids(self, a, b, g):\n",
    "        \"\"\"This function creates IDs for the three agents to \n",
    "           enable the scheduler to know them.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        a: interger\n",
    "            ID for agent type a\n",
    "        b: interger\n",
    "            ID for agent type b\n",
    "        g: interger\n",
    "            ID for agent type g\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        a_ids, b_ids, g_ids : tuple\n",
    "            a tuple containing ID lists of the three agents.     \n",
    "        \"\"\"\n",
    "        a_ids = self.assign_list[0:a]\n",
    "        b_ids = self.assign_list[a: (a + b)]\n",
    "        g_ids = self.assign_list[(a + b):]\n",
    "        \n",
    "        return (a_ids, b_ids, g_ids)\n",
    "    \n",
    "    def __add_agent_list_to_schedule(self, id_list, agent_type):\n",
    "        \"\"\"This function adds all the created agents to the \n",
    "           schedule in readiness for movement.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        id_list: list\n",
    "            List containing as a set of IDs for a given agent type\n",
    "        agent_type: string\n",
    "            Agent type, can either be a(alpha), b(beta) or g(gamma)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        agent_details : tuple\n",
    "            Contains agent type and location in the grid.     \n",
    "        \"\"\"\n",
    "        for i in id_list:            # Iterate over the agent's ID list\n",
    "            a = agent_type(i, self)\n",
    "            \n",
    "            ## Adds the created agents to the schedule, so the scheduler knows they are there, and can move them\n",
    "            ## at each time tick.\n",
    "            self.schedule.add(a)\n",
    "            \n",
    "            ## Add the agent to a random grid cell at some random x and random y\n",
    "            x = self.random.randrange(self.grid.width)\n",
    "            y = self.random.randrange(self.grid.height)\n",
    "            \n",
    "            ##  Can be read as place agent a at the coordinate tuple in the grid\n",
    "            agent_results = self.grid.place_agent(a, (x, y))\n",
    "    \n",
    "    def __init__(self, N, width, height, a, b, g):\n",
    "        \"\"\"This function creates and hold the agents properties.\n",
    "           It Takes in its name and some number of agents, assigns \n",
    "           the number to attribute .num_agents.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        N: interger\n",
    "            The number of each agent.\n",
    "        width: interger\n",
    "            X axis of the grid\n",
    "        height: interger\n",
    "            y axis of the grid\n",
    "        a: interger\n",
    "            alpha agent\n",
    "        b: interger\n",
    "            beta agent\n",
    "        g: interger\n",
    "            gamma agent\n",
    "        \"\"\"\n",
    "        self.num_agents = N\n",
    "        \n",
    "        self.assign_list = list(range(N))\n",
    "        self.a_agents = int(N * a)\n",
    "        self.b_agents = int(N * b)\n",
    "        self.g_agents = int(N * g)\n",
    "        \n",
    "        ## The mesa MultiGrid class exists to handle a spatial grid and comes with its own methods, \n",
    "        ## which we will use below (as self.grid)\n",
    "        self.grid = MultiGrid(width, height, False)\n",
    "        \n",
    "        ## This creates the inverse distance matrix, which is comprised of the inverse distance between every cell\n",
    "        ## in the grid and every other cell.  The first layer/matrix starts at position 0,0, moves to the right, then\n",
    "        ## translates down one row, repeated till finished.\n",
    "        self.id_matrix = self.__id_matrix()\n",
    "        \n",
    "        ## Creates and empty grid of zeros. We'll need this for multiplication and summation later on.\n",
    "        self.empty =  np.zeros((self.grid.width, self.grid.height))\n",
    "        \n",
    "        ## This is the schedule for the entire model.  It sets the activation environment such that at each\n",
    "        ## model time tick, which agent goes first is randomly decided.\n",
    "        self.schedule = RandomActivation(self)\n",
    "        \n",
    "        ## Creates the agents, instantiating them with the properties of the DiploAgent class.\n",
    "        self.a_ids, self.b_ids, self.g_ids = self.__get_ids(self.a_agents, self.b_agents, self.g_agents)\n",
    "        \n",
    "        ## All AlphaAgents get the same course of action\n",
    "        self.a_assigned = self.__add_agent_list_to_schedule(self.a_ids, AlphaAgent)\n",
    "        \n",
    "        ## All AlphaAgents get the same course of action\n",
    "        self.b_assigned = self.__add_agent_list_to_schedule(self.b_ids, BetaAgent)\n",
    "        \n",
    "        ## All AlphaAgents get the same course of action\n",
    "        self.g_assigned = self.__add_agent_list_to_schedule(self.g_ids, GammaAgent)\n",
    "        \n",
    "        ## This instantiates the agent counts per cell, and the IDW matrix (heat map) as a result of that.  \n",
    "        ## This is called on initialization of the class because we need the values of the IDW to move the agent.\n",
    "        self.valence_sum = self.__valence_sum()\n",
    "        self.IDW_matrix = self.__IDW_matrix() \n",
    "        \n",
    "        ## Ok, this is implementing the output of the DataCollector method INTO a MoneyModel attribute called\n",
    "        ## datacollector.  It looks a little wonky but two parameters to DataCollector are being passed, both\n",
    "        ## as dictionaries.\n",
    "        self.valence_out = DataCollector(agent_reporters={\"Valence\": \"valence\"})\n",
    "        self.coa_out = DataCollector(agent_reporters={\"COA\": \"action_course\"})\n",
    "        \n",
    "    def step(self):\n",
    "        \"\"\"Advance the model by one step by collecting the data at each step, \n",
    "           and then, taking the schedule, activating the agents in the specified\n",
    "           order and they execute their actions. It also updates the environment.\n",
    "        \"\"\"\n",
    "        self.valence_out.collect(self)\n",
    "        self.coa_out.collect(self)\n",
    "        self.schedule.step()\n",
    "        self.valence_sum = self.__valence_sum()\n",
    "        self.IDW_matrix = self.__IDW_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2872c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiploAgent(Agent):\n",
    "    \n",
    "    \"\"\"This is an agent with fixed initial wealth.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, unique_id, model):  \n",
    "        \"\"\"This function initializes the object as an instance of Agent.\n",
    "        \"\"\"\n",
    "        ## Super inherits id and model from the Agent class.\n",
    "        super().__init__(unique_id, model)\n",
    "        self.wealth = 1\n",
    "    \n",
    "    def move(self):\n",
    "        \"\"\"This function moves the agents within the multigrid based on the\n",
    "           course of action as both specified in the DiploModel class.\n",
    "        \"\"\"\n",
    "        ## This defines the neighborhood (moore = queen's adjacency, like chess) \n",
    "        ## that the agent can move within each step\n",
    "        possible_steps = self.model.grid.get_neighborhood(self.pos, moore = True, include_center = False, radius = 1)\n",
    "        ## Instantiates the list of IDW values for the agent neighborhood\n",
    "        IDW_vals = []\n",
    "        \n",
    "        ## Grabs the coordinates of the possible steps and then....\n",
    "        for i in possible_steps:\n",
    "            x = i[0]\n",
    "            y = i[1]\n",
    "        \n",
    "            ## Appends the IDW values of the neighborhood cells into a list\n",
    "            IDW_vals += [self.model.IDW_matrix[x][y]]\n",
    "            \n",
    "        ## Which becomes an array so I can use numpy functions because it's easier\n",
    "        IDW_vals = np.array(IDW_vals)\n",
    "        \n",
    "        ## Generates a random integer 0-9 inclusive.\n",
    "        rand = random.randint(0, 9)\n",
    "        \n",
    "        ## If the agent has no coa(action_course), then it has a 20% chance of moving to the minimum value cell, \n",
    "        ## a 20% chance of moving to the maximum value cell, and a 60% chance of moving randomly.\n",
    "        if self.action_course == None:\n",
    "            if rand <= 1:   \n",
    "                new_loc = possible_steps[IDW_vals.argmin()]                \n",
    "            elif 1 < rand <= 3:              \n",
    "                new_loc = possible_steps[IDW_vals.argmax()]            \n",
    "            else:          \n",
    "                new_loc = self.random.choice(possible_steps)\n",
    "                \n",
    "        ## if the agent valence is less than 0, there is a 70% chance the agent moves randomly.  \n",
    "        ## A 30% chance it moves either to the argmin or argmax, depending on its COA.  The idea is that\n",
    "        ## self-interested/negatively interested agents can still segregate into the right COA neighborhood,\n",
    "        ## but they retain their \"negative\" characteristics.\n",
    "        elif self.valence < 0:        \n",
    "            if rand <= 3:             \n",
    "                if self.action_course != 1:\n",
    "                    new_loc = possible_steps[IDW_vals.argmin()]         \n",
    "                else:\n",
    "                    new_loc = possible_steps[IDW_vals.argmax()]\n",
    "            else:\n",
    "                new_loc = self.random.choice(possible_steps)\n",
    "                \n",
    "        ## and finally if the agent valence is greater than zero, there is a 30% chance it moves to the arg max, \n",
    "        ## and a 70% chance it moves randomly.\n",
    "        else:\n",
    "            if rand <= 3:\n",
    "                new_loc = possible_steps[IDW_vals.argmax()] \n",
    "            else: \n",
    "                new_loc = self.random.choice(possible_steps)  \n",
    "                \n",
    "        ## And this assigns it to the new position, calling on the model.grid function\n",
    "        self.model.grid.move_agent(self, new_loc)\n",
    "        \n",
    "    def convince (self):\n",
    "        \"\"\"Creates a method where the agent gives money to \n",
    "           another Agent only if they occupy the same cell.\n",
    "        \"\"\"\n",
    "        \n",
    "        ## This calls the Model class grid.get_cell_list_contents, which takes a list of \n",
    "        ## position coords in this case the self-position, and returns what else is in the cell.\n",
    "        cellmates = self.model.grid.get_cell_list_contents([self.pos])\n",
    "        \n",
    "        ## This conditional says - if there is anything in the cell but you, then randomly choose \n",
    "        ## another agent and try to convince it of your point of view, if it doesn't have a COA.\n",
    "        if len(cellmates) > 1:\n",
    "            for others in cellmates:               \n",
    "                if others.action_course == None:\n",
    "                    others.action_course = self.action_course \n",
    "                    if self.valence < 0:                    \n",
    "                        others.valence = others.valence * -1\n",
    "    def step(self):\n",
    "        \"\"\"It defines what the agent will do for each step of the model.\n",
    "        \"\"\"\n",
    "        self.convince()\n",
    "        self.move()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "372666da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaAgent(DiploAgent):\n",
    "    \n",
    "    \"\"\"\n",
    "    This agent is an initiator of action/response to \n",
    "    change in stimulation.  From a diplomacy perspective \n",
    "    they are trying to gain compliance from others to go \n",
    "    along with/enact a particular course of action.\n",
    "    They are \"principled,\"in the sense that they are \n",
    "    acting out of concern for the group. (this does \n",
    "    not make them \"nice\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, unique_id, model):\n",
    "        super().__init__(unique_id, model)\n",
    "        \n",
    "        self.valence = 1\n",
    "        self.action_course = 1\n",
    "\n",
    "class BetaAgent(DiploAgent):\n",
    "    \n",
    "    \"\"\"\n",
    "    This agent is a (potential) supporters of change.  \n",
    "    They are completely open to being convinced one way \n",
    "    or the other. What will convince them varies.  They \n",
    "    can be convinced by any actor that has a COA.  When \n",
    "    convinced, they will adopt the valence sign of whoever \n",
    "    convinced them.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, unique_id, model):\n",
    "        super().__init__(unique_id, model)\n",
    "        \n",
    "        self.valence = 0.5\n",
    "        self.action_course = None\n",
    "        \n",
    "class GammaAgent(DiploAgent):\n",
    "    \n",
    "    \"\"\"\n",
    "    This agent is \"unprincipled\" agents, in that their primary concern is \n",
    "    whether or not the course of action benefits them. In general, change \n",
    "    has unknowns.  Unknowns create risk.  GammaAgents can be thought of as \n",
    "    having a high aversion to PERSONAL risk, while not caring about \n",
    "    collective risk (except as it relates to the former).  Unless proposed \n",
    "    actions happen to align with their sense of personal gain, they will \n",
    "    not support the actions.  By definition, this is a narrow intersection \n",
    "    window (on average).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, unique_id, model):\n",
    "        super().__init__(unique_id, model)\n",
    "        \n",
    "        self.valence = -1\n",
    "        self.action_course = course_of_action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dab5b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Instantiates the model and runs it\n",
    "mod1_list = []\n",
    "\n",
    "for i in range(50):\n",
    "    model1 = DiploModel(100, 25, 25, 0.23, 0.69, 0.08)\n",
    "    for j in range(500):\n",
    "        model1.step()\n",
    "    agent_valences = model1.valence_out.get_agent_vars_dataframe()\n",
    "    agent_coas = model1.coa_out.get_agent_vars_dataframe()\n",
    "\n",
    "    mod1_list += [(agent_valences, agent_coas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0534dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Instantiates the model and runs it\n",
    "mod2_list = []\n",
    "\n",
    "for i in range(50):\n",
    "    model2 = DiploModel(500, 25, 25, 0.23, 0.69, 0.08)\n",
    "    for j in range(500):\n",
    "        model2.step()\n",
    "    agent_valences = model2.valence_out.get_agent_vars_dataframe()\n",
    "    agent_coas = model2.coa_out.get_agent_vars_dataframe()\n",
    "\n",
    "    mod2_list += [(agent_valences, agent_coas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5d31c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Instantiates the model and runs it\n",
    "mod3_list = []\n",
    "\n",
    "for i in range(50):\n",
    "    model3 = DiploModel(100, 25, 25, 0.15, 0.70, 0.15)\n",
    "    \n",
    "    for j in range(500):\n",
    "        model3.step()\n",
    "    agent_valences = model3.valence_out.get_agent_vars_dataframe()\n",
    "    agent_coas = model3.coa_out.get_agent_vars_dataframe()\n",
    "\n",
    "    mod3_list += [(agent_valences, agent_coas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c24db714",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Instantiates the model and runs it\n",
    "mod4_list = []\n",
    "\n",
    "for i in range(50):\n",
    "    model4 = DiploModel(500, 25, 25, 0.15, 0.70, 0.15)\n",
    "    for j in range(500):\n",
    "        model4.step()\n",
    "    agent_valences = model4.valence_out.get_agent_vars_dataframe()\n",
    "    agent_coas = model4.coa_out.get_agent_vars_dataframe()\n",
    "\n",
    "    mod4_list += [(agent_valences, agent_coas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ba41e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip(model_list):\n",
    "    unzip = list(zip(*model_list))\n",
    "    valence = unzip[0]\n",
    "    coas = unzip[1]\n",
    "    \n",
    "    return (valence, coas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b0d2e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_valence(valence_list):\n",
    "    min_valence = []\n",
    "    for i in range(0,500):\n",
    "        min_valence += [(valence_list.xs(i, level = \"Step\")[\"Valence\"].sum())]\n",
    "\n",
    "    min_array = np.array(min_valence)\n",
    "    out_idx = np.argmin(min_array)\n",
    "    return(out_idx)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6a29ba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_valence_timestep(l_of_valence_list):\n",
    "    out_list = [get_min_valence(i) for i in l_of_valence_list]\n",
    "    \n",
    "    return(np.array(out_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a44d0473",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1_val, mod1_coas = unzip(mod1_list)\n",
    "mod2_val, mod2_coas = unzip(mod2_list)\n",
    "mod3_val, mod3_coas = unzip(mod3_list)\n",
    "mod4_val, mod4_coas = unzip(mod4_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c6dee021",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1_min_val_timestep = get_min_valence_timestep(mod1_val)\n",
    "mod2_min_val_timestep = get_min_valence_timestep(mod2_val)\n",
    "mod3_min_val_timestep = get_min_valence_timestep(mod3_val)\n",
    "mod4_min_val_timestep = get_min_valence_timestep(mod4_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9880c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1_mean, mod1_std = mod1_min_val_timestep.mean(), mod1_min_val_timestep.std()\n",
    "mod2_mean, mod2_std = mod2_min_val_timestep.mean(), mod2_min_val_timestep.std()\n",
    "mod3_mean, mod3_std = mod3_min_val_timestep.mean(), mod3_min_val_timestep.std()\n",
    "mod4_mean, mod4_std = mod4_min_val_timestep.mean(), mod4_min_val_timestep.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "201612ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.86 27.893375557648092\n",
      "18.62 7.98471038923767\n",
      "67.14 50.28240646588029\n",
      "14.82 4.914020756976917\n"
     ]
    }
   ],
   "source": [
    "print(mod1_mean, mod1_std)\n",
    "print(mod2_mean, mod2_std)\n",
    "print(mod3_mean, mod3_std)\n",
    "print(mod4_mean, mod4_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
